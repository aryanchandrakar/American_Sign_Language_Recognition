{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "American_Sign_Language_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanchandrakar/American_Sign_Language_Recognition/blob/main/American_Sign_Language_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OoFRINJqUON"
      },
      "source": [
        "# **AMERICAN SIGN LANGUAGE RECOGNITION PROJECT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOkrMX7pltRV"
      },
      "source": [
        "# Setting up the environment and kaggle API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPvr1WtWkxCA"
      },
      "source": [
        "**Importing tensorflow and checking tensorflow:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UOYnjDtxOfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f142ca-40cd-4624-ca2d-dd2894739031"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WyrqUq3lS_h"
      },
      "source": [
        "# Downloading the grassknoted/asl-alphabet available [here](https://www.kaggle.com/grassknoted/asl-alphabet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K4MHAy0l86n"
      },
      "source": [
        "**Extracting the contents:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTM_VxUV0bZT"
      },
      "source": [
        "!unzip /content/asl_alphabet_test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYbtIPMR80N3"
      },
      "source": [
        "!unzip /content/asl_alphabet_train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2-_cTFamgpu"
      },
      "source": [
        "# Looking at the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvslYmS1mk-H"
      },
      "source": [
        "**Specifying train and test directories:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSY7woTT0nrC"
      },
      "source": [
        "# Specifying the training and test directories\n",
        "\n",
        "TRAINING_DIR = '/content/asl_alphabet_train/'\n",
        "TEST_DIR = '/content/asl_alphabet_test'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RkBWLZ-mr-z"
      },
      "source": [
        "**Looking at some random images from the dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E01oqNN5zvF"
      },
      "source": [
        "# Printing 5 random images from any training category or from a specified category\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "number_of_rows = 1\n",
        "number_of_columns = 5\n",
        "\n",
        "categories = os.listdir(TRAINING_DIR)\n",
        "\n",
        "random.seed(13)\n",
        "\n",
        "category = categories[random.randint(1, 30)]\n",
        "# category = 'A'\n",
        "\n",
        "for i in range(number_of_columns):\n",
        "  subplot = plt.subplot(number_of_rows, number_of_columns, i + 1)\n",
        "  subplot.axis('Off')\n",
        "  subplot.set_title(category)\n",
        "  image_path = os.path.join(\n",
        "      TRAINING_DIR,\n",
        "      str(category),\n",
        "      str(category) + str(random.randint(1, 1000)) + '.jpg'\n",
        "  )\n",
        "  image = mpimg.imread(image_path)\n",
        "  plt.imshow(image)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNMwACdkmxzb"
      },
      "source": [
        "# Preparing the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFowqDJ_m5Uh"
      },
      "source": [
        "**Augmenting the data with brightness and zoom ranges:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WAWg_u617Fw"
      },
      "source": [
        "# Preparing ImageDataGenerator object for training the model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SIZE = 200\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    samplewise_center=True, \n",
        "    samplewise_std_normalization=True,\n",
        "    brightness_range=[0.8, 1.0],\n",
        "    zoom_range=[1.0, 1.2],\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, seed=13,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, seed=13,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Uvq3DOnQdF"
      },
      "source": [
        "# Preparing the model for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCD_SGLFnKnk"
      },
      "source": [
        "**Downloading custom weight file if required:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjX76h9Y7ya3"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-D_ejimn4Ll"
      },
      "source": [
        "**Preparing Inception V3 Network for transfer learning:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4GFWxTZLWVM"
      },
      "source": [
        "# Loading inception v3 network for transfer learning\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "WEIGHTS_FILE = './inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "inception_v3_model = InceptionV3(\n",
        "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3), \n",
        "    include_top = False, \n",
        "    weights = 'imagenet'\n",
        ")\n",
        "\n",
        "# Not required --> inception_v3_model.load_weights(WEIGHTS_FILE)\n",
        "\n",
        "# Enabling the top 2 inception blocks to train\n",
        "for layer in model.layers[:249]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "    layer.trainable = True\n",
        "    \n",
        "# Checking model summary to pick a layer (if required)\n",
        "inception_v3_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-8fgl6noAiV"
      },
      "source": [
        "**Choosing the inception output layer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8YjOsgxMtDe"
      },
      "source": [
        "# Choosing the output layer to be merged with our FC layers (if required)\n",
        "inception_output_layer = inception_v3_model.get_layer('mixed7')\n",
        "print('Inception model output shape:', inception_output_layer.output_shape)\n",
        "\n",
        "# Not required --> inception_output = inception_output_layer.output\n",
        "inception_output = inception_v3_model.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ifJCgHaoFKm"
      },
      "source": [
        "**Adding our own set of fully connected layers at the end of Inception v3 network:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ic3Lj_pNceH"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(inception_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Not required --> x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense(29, activation='softmax')(x)           \n",
        "\n",
        "model = Model(inception_v3_model.input, x) \n",
        "\n",
        "model.compile(\n",
        "    optimizer=SGD(lr=0.0001, momentum=0.9),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFoNKcvkoWA2"
      },
      "source": [
        "**Looking at the final model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMw3sy6fOS2G"
      },
      "source": [
        "# Watch the new model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBsj6WNwocPI"
      },
      "source": [
        "**Setting up a callback funtion in order to stop training at a particular threshold:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlbZNjuQOsU3"
      },
      "source": [
        "# Creating a callback to stop model training after reaching a threshold accuracy\n",
        "\n",
        "LOSS_THRESHOLD = 0.2\n",
        "ACCURACY_THRESHOLD = 0.95\n",
        "\n",
        "class ModelCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('val_loss') <= LOSS_THRESHOLD and logs.get('val_acc') >= ACCURACY_THRESHOLD:\n",
        "      print(\"\\nReached\", ACCURACY_THRESHOLD * 100, \"accuracy, Stopping!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = ModelCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_5UfCiqolY5"
      },
      "source": [
        "# Training the model generated using Inception v3 and our own set of Fully Connected layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYqSIy_yotLt"
      },
      "source": [
        "**Fitting the model to the training dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoW7U7q3OYpo"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=50,\n",
        "    epochs=50,\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CXVnAVsoyqJ"
      },
      "source": [
        "# Plotting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt5LoQJxo7VJ"
      },
      "source": [
        "**Training Accuracy vs Validation Accuracy:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBj0wfCzPi_v"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1PujB-rpCf9"
      },
      "source": [
        "**Training Loss vs Validation Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu43kLYFbgFO"
      },
      "source": [
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwrRQ5vDpNbk"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2325qEL9pRTD"
      },
      "source": [
        "**As we were satisfied with our results we save our model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw-o3Y99bwsA"
      },
      "source": [
        "# Saving the model\n",
        "MODEL_NAME = 'models/asl_alphabet_{}.h5'.format(9575)\n",
        "model.save(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I9gowc4peGC"
      },
      "source": [
        "# Testing our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdNidh7ipqCA"
      },
      "source": [
        "**Plotting images along with their respective actual and predicted classes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yfh2vDvcGnN"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = os.listdir(TRAINING_DIR)\n",
        "classes.sort()\n",
        "\n",
        "for i, test_image in enumerate(os.listdir(TEST_DIR)):\n",
        "    image_location = TEST_DIR + test_image\n",
        "    img = cv2.imread(image_location)\n",
        "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    plt.figure()\n",
        "    plt.axis('Off')\n",
        "    plt.imshow(img)\n",
        "    img = np.array(img) / 255.\n",
        "    img = img.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    img = data_generator.standardize(img)\n",
        "    prediction = np.array(model.predict(img))\n",
        "    actual = test_image.split('_')[0]\n",
        "    predicted = classes[prediction.argmax()]\n",
        "    print('Actual class: {} \\n Predicted class: {}'.format(actual, predicted))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgA2-ZlTp5Os"
      },
      "source": [
        "**Calculating test accuracy:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mw1idlweewd"
      },
      "source": [
        "test_images = os.listdir(TEST_DIR)\n",
        "total_test_cases = len(test_images)\n",
        "total_correctly_classified = 0\n",
        "total_misclassified = 0\n",
        "for i, test_image in enumerate(test_images):\n",
        "    image_location = TEST_DIR + test_image\n",
        "    img = cv2.imread(image_location)\n",
        "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    img = np.array(img) / 255.\n",
        "    img = img.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    img = data_generator.standardize(img)\n",
        "    prediction = np.array(model.predict(img))\n",
        "    actual = test_image.split('_')[0]\n",
        "    predicted = classes[prediction.argmax()]\n",
        "    print('Actual class: {} - Predicted class: {}'.format(\n",
        "        actual, predicted), end=' ')\n",
        "    if actual == predicted:\n",
        "      print('PASS!')\n",
        "      total_correctly_classified += 1\n",
        "    else:\n",
        "      print('FAIL!')\n",
        "      total_misclassified += 1\n",
        "print(\"=\" * 20)\n",
        "test_accuracy = (total_correctly_classified / total_test_cases) * 100\n",
        "test_error_rate = (total_misclassified / total_test_cases) * 100\n",
        "\n",
        "print('Test accuracy (%):', test_accuracy)\n",
        "print('Test error rate (%):', test_error_rate)\n",
        "print('Number of misclassified classes:', total_misclassified)\n",
        "print('Number of correctly classified classes', total_correctly_classified)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC_IM6Dzjmp8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}